# Raport
## Evaluation of Popular Writing Assistance Libraries in Python

The objective of this project was to identify two popular Python libraries for writing assistance, create metrics to evaluate their performance, and compare the results to understand each library's strengths, weaknesses, and potential areas for improvement.

I selected pyspellchecker and TextBlob for this comparison. Due to time constraints and technical issues, I used manually generated data instead of data sourced from websites.

### Methodology and Results

The evaluation showed that pyspellchecker generally outperforms TextBlob in terms of accuracy, although TextBlob is slightly faster. One of the main challenges I encountered was in defining and implementing appropriate metrics. While implementing the libraries was straightforward, understanding how the metrics relate to the overall efficiency and effectiveness of the models was more complex.
### Challenges
Defining Metrics: Understanding the meaning of each metric and translating that into script form was more difficult than anticipated.
Interpreting Results: Another challenge was understanding how each metric impacts the library's effectiveness, which required further investigation into the correlation between metrics and model efficiency.

### Conclusion
This evaluation highlighted pyspellchecker's stronger performance in accuracy and TextBlob's speed advantage. Further work could explore additional metrics and improvements to enhance both librariesâ€™ performance.